{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries\n",
    "import nltk\n",
    "import random\n",
    "#importing a dataset with 1000 positive reviews and 1000 negative reviews\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import pickle\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from nltk.classify import ClassifierI\n",
    "from statistics import mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a big list containing words and their associated category.\n",
    "documents = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((list(movie_reviews.words(fileid)),category))\n",
    "\n",
    "random.shuffle(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all the words into lowercase and appending it into an empty list\n",
    "all_words =[]\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower()) \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a list of the 3000 commonly used words\n",
    "word_features = list(all_words.keys())[:3000]\n",
    "\n",
    "#a function that checks whether the 3000 commonly used words present \n",
    "#in the negative review pile or the positive review pile\n",
    "def find_features(document):\n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    return features\n",
    "# a list containing the commonly used words and whether it is \n",
    "#present in positive reviews or negative\n",
    "featuresset =[]\n",
    "for (rev,category) in documents:\n",
    "    featuresset.append((find_features(rev),category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:  69.0\n"
     ]
    }
   ],
   "source": [
    "#creating training and testing set\n",
    "training_set =  featuresset[1900:]\n",
    "test_set = featuresset[:1900]\n",
    "#using Naive Bayes classifier to check\n",
    "#classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
    "classifier_f = open(\"naivebayes.pickle\",\"rb\")\n",
    "classifier = pickle.load(classifier_f)\n",
    "classifier_f.close()\n",
    "print(\"Test: \",(nltk.classify.accuracy(classifier,test_set))*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsave_classifier = open(\"naivebayes.pickle\",\"wb\")\\npickle.dump(classifier,save_classifier)\\nsave_classifier.close()\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "save_classifier = open(\"naivebayes.pickle\",\"wb\")\n",
    "pickle.dump(classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier  = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(training_set)\n",
    "print(\"MNB_classifier: \",(nltk.classify.accuracy(MNB_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier  = SklearnClassifier(MultinomialNB())\n",
    "BernoulliNB_classifier.train(training_set)\n",
    "print(\"BernoulliNB_classifier: \",(nltk.classify.accuracy(BernoulliNB_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_classifier  = SklearnClassifier(MultinomialNB())\n",
    "LogisticRegression_classifier.train(training_set)\n",
    "print(\"LogisticRegression_classifier: \",(nltk.classify.accuracy(LogisticRegression_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier  = SklearnClassifier(MultinomialNB())\n",
    "SGDClassifier_classifier.train(training_set)\n",
    "print(\"SGDClassifier_classifier: \",(nltk.classify.accuracy(SGDClassifier_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier  = SklearnClassifier(MultinomialNB())\n",
    "SVC_classifier.train(training_set)\n",
    "print(\"SVC_classifier: \",(nltk.classify.accuracy(SVC_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier  = SklearnClassifier(MultinomialNB())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC_classifier: \",(nltk.classify.accuracy(LinearSVC_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NuSVC_classifier:  66.84210526315789\n"
     ]
    }
   ],
   "source": [
    "NuSVC_classifier  = SklearnClassifier(MultinomialNB())\n",
    "NuSVC_classifier.train(training_set)\n",
    "print(\"NuSVC_classifier: \",(nltk.classify.accuracy(NuSVC_classifier,test_set))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
